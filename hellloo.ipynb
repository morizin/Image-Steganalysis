{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import math, re, os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load label and paths"},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_path(pre):\n    return np.vectorize(lambda file: os.path.join('/kaggle/input/alaska2-image-steganalysis', pre, file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/alaska2-image-steganalysis/sample_submission.csv')\ntrain_filenames = np.array(os.listdir(\"/kaggle/input/alaska2-image-steganalysis/Cover/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(0)\npositives = train_filenames.copy()\nnegatives = train_filenames.copy()\nnp.random.shuffle(positives)\nnp.random.shuffle(negatives)\n\njmipod = append_path('JMiPOD')(positives[:2000])\njuniward = append_path('JUNIWARD')(positives[10000:12000])\nuerd = append_path('UERD')(positives[20000:22000])\n\n# pos_paths = np.concatenate([jmipod, juniward, uerd])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_paths = append_path('Test')(sub.Id.values)\nneg_paths = append_path('Cover')(negatives[:2000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Do all the imports\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport os\nimport glob\nfrom skimage.feature import hog\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\n# from kaggle_datasets import KaggleDatasets\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom scipy.ndimage.measurements import label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \n#Define functions that will be used later\n\ndef color_hist(img, nbins=32, bins_range=(0, 256)):\n    # Compute the histogram of the RGB channels separately\n    fhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range) #First channel histogram\n    shist = np.histogram(img[:,:,1], bins=nbins, range=bins_range) # Second channel histogram\n    thist = np.histogram(img[:,:,2], bins=nbins, range=bins_range) # Third channel histogram\n    # Generating bin centers\n    bin_edges = fhist[1]\n    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n    # Concatenate the histograms into a single feature vector\n    hist_features = np.concatenate((fhist[0], shist[0], thist[0]))\n    # Return the individual histograms, bin_centers and feature vector\n    return hist_features, fhist, shist, thist, bin_centers\n\ndef bin_spatial_features(img, size=(16, 16)):\n    # Use cv2.resize().ravel() to create the feature vector\n    features = cv2.resize(img, size).ravel() \n    # Return the feature vector\n    return features\n\ndef get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n     if vis == True:   \n       features,hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n                        visualize = vis,feature_vector=feature_vec)\n       return features,hog_image\n     else:\n        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n                        visualize = vis,feature_vector=feature_vec)\n        return features\n\ndef extract_features_hog(imgs, cspace='RGB', orient=9, \n                        pix_per_cell=8, cell_per_block=2, hog_channel=0):\n    # Create a list to append feature vectors to\n    features = []\n    # Iterate through the list of images\n    for file in imgs:\n        # Read in each one by one\n        image = cv2.imread(file)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert to RGB color space\n        # apply color conversion if other than 'RGB'\n        if cspace != 'RGB':\n            if cspace == 'HSV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n            elif cspace == 'LUV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n            elif cspace == 'HLS':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n            elif cspace == 'YUV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n            elif cspace == 'YCrCb':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n        else: feature_image = np.copy(image)      \n \n        # Call get_hog_features() with vis=False, feature_vec=True\n        if hog_channel == 'ALL':\n            hog_features = []\n            for channel in range(feature_image.shape[2]):\n                hog_features.append(get_hog_features(feature_image[:,:,channel], \n                                    orient, pix_per_cell, cell_per_block, \n                                    vis=True, feature_vec=True))\n            hog_features = np.ravel(hog_features)        \n        else:\n            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n                        pix_per_cell, cell_per_block, vis=True, feature_vec=True)\n        # Append the new feature vector to the features list\n        features.append(hog_features)\n    # Return list of feature vectors\n    return features\n\ndef color_hist_features(img, nbins=32, bins_range=(0, 256)):\n    # Compute the histogram of the color channels separately\n    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n    # Concatenate the histograms into a single feature vector\n    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n    # Return the individual histograms, bin_centers and feature vector\n    return hist_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at color features\n#Spatial binned features comparison for car and notcar\n\ndef bin_spatial(img, color_space='RGB', size=(16, 16)): \n    if color_space!= 'RGB':\n        if color_space == 'HSV':\n            feature_image = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n        elif color_space == 'HLS':\n            feature_image = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n        elif color_space == 'LUV':\n            feature_image = cv2.cvtColor(img,cv2.COLOR_RGB2LUV)\n        elif color_space == 'YUV':\n            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n        elif color_space == 'YCrCb':\n            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n    else: feature_image = np.copy(img) \n    resize = cv2.resize(feature_image, size)\n    features = resize.ravel()\n    \n    # Return the feature vector\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pickle\n#Function reads images, extract features and returns a list of feature vectors\n\ndef extract_features_color(imgs, cspace='HLS',spatial_size=(16, 16),\n                        hist_bins=16, hist_range=(0, 256)):\n    # Create a list to append feature vectors to\n    features = []\n    for file in imgs:\n        # Read in each one by one\n        image = cv2.imread(file)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert to RGB color space\n        \n        spatial_features = bin_spatial(image, color_space=cspace, size= spatial_size)\n        hist_features = color_hist_features(image, nbins=hist_bins, bins_range=hist_range)\n    \n        features.append(np.concatenate((spatial_features, hist_features)))\n \n        \n    return features\n \n# # car_features_color = extract_features_color(cars, cspace='RGB', spatial_size=(16, 16), hist_bins=32, hist_range=(0, 256))\n# # pickle.dump('car_color',car_features_color)\n# # notcar_features_color = extract_features_color(notcars, cspace='RGB', spatial_size=(16, 16), hist_bins=32, hist_range=(0, 256))\n# # pickle.dump('notcar_color',notcar_features_color)\n# print(len(car_features_color), len(notcar_features_color))\n# print(len(car_features_color[0]), len(notcar_features_color[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training using color and HOG features\n#Selected color features - cspace = 'RGB' and spatial_size = 16,16\n# from numba import jit, cuda\nfrom sklearn.preprocessing import StandardScaler\ndef extract_features(imgs, color_space='RGB', spatial_size=(16, 16),\n                        hist_bins=32, orient=9, \n                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n                        spatial_feat=True, hist_feat=True, hog_feat=True):\n\n    # Create a list to append feature vectors to\n    features = []\n    num = 0\n    # Iterate through the list of images\n    for file in imgs:\n        file_features = []\n        # Read in each one by one\n        image = cv2.imread(file)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert to RGB color space\n        # apply color conversion if other than 'RGB'\n        if color_space != 'RGB':\n            if color_space == 'HSV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n            elif color_space == 'LUV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n            elif color_space == 'HLS':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n            elif color_space == 'YUV':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n            elif color_space == 'YCrCb':\n                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n        else: feature_image = np.copy(image)      \n        \n        if spatial_feat == True:\n            spatial_features = bin_spatial_features(feature_image, size=spatial_size)\n            file_features.append(spatial_features)\n            \n        if hist_feat == True:\n            # Apply color_hist()\n            hist_features = color_hist_features(feature_image, nbins=hist_bins)\n            file_features.append(hist_features)\n            \n        if hog_feat == True:\n        # Call get_hog_features() with vis=False, feature_vec=True\n            if hog_channel == 'ALL':\n                hog_features = []\n                for channel in range(feature_image.shape[2]):\n                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n                                        orient, pix_per_cell, cell_per_block, \n                                        vis=False, feature_vec=True))\n                hog_features = np.ravel(hog_features)        \n            else:\n                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n            # Append the new feature vector to the features list\n            \n            file_features.append(hog_features)\n        num+=1\n        if num%100==0:\n            print('finished',num)\n          \n        features.append(np.concatenate(file_features))\n   \n    # Return list of feature vectors\n    return features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dist/jpegio-x.x.x-cp3x-cp3x-win_amd64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train classifier using HOG and color features\n# from numba import jit, cuda\nfrom multiprocessing import Process\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nimport time\nimport joblib \nfrom sklearn.model_selection import train_test_split\n\n### TODO: Tweak these parameters and see how the results change.\ncolor_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\norient = 18  # HOG orientations\npix_per_cell = 64 # HOG pixels per cell #16\ncell_per_block = 1 # HOG cells per block #2\nhog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\nspatial_size = (16, 16) # Spatial binning dimensions\nhist_bins = 16    # Number of histogram bins\nspatial_feat = False # Spatial features on or off\nhist_feat = False # Histogram features on or off\nhog_feat = True # HOG features on or off\ny_start_stop = [None, None] # Min and max in y to search in slide_window()\n\nprint('Hello')                         \njmipod_features = extract_features(jmipod, color_space=color_space, \n                        spatial_size=spatial_size, hist_bins=hist_bins, \n                        orient=orient, pix_per_cell=pix_per_cell, \n                        cell_per_block=cell_per_block, \n                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n                        hist_feat=hist_feat, hog_feat=hog_feat)\n\nprint('Hello')\n\njoblib.dump(jmipod_features,'jmipod_feature.pkl')\n\ncover_features = extract_features(neg_paths, color_space=color_space, \n                        spatial_size=spatial_size, hist_bins=hist_bins, \n                        orient=orient, pix_per_cell=pix_per_cell, \n                        cell_per_block=cell_per_block, \n                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n                        hist_feat=hist_feat, hog_feat=hog_feat)\nprint('Hello')\n\njoblib.dump(cover_features,'cover_feature.pkl')\nuerd_features = extract_features(uerd, color_space=color_space, \n                        spatial_size=spatial_size, hist_bins=hist_bins, \n                        orient=orient, pix_per_cell=pix_per_cell, \n                        cell_per_block=cell_per_block, \n                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n                        hist_feat=hist_feat, hog_feat=hog_feat)\nprint('Hello')\n\njoblib.dump(uerd_features,'uerd_feature.pkl')\njuniward_features = extract_features(juniward, color_space=color_space, \n                        spatial_size=spatial_size, hist_bins=hist_bins, \n                        orient=orient, pix_per_cell=pix_per_cell, \n                        cell_per_block=cell_per_block, \n                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n                        hist_feat=hist_feat, hog_feat=hog_feat)\nprint('Hello')\n\njoblib.dump(juniward_features,'juniward_feature.pkl')\ntest_features = extract_features(test_paths, color_space=color_space, \n                        spatial_size=spatial_size, hist_bins=hist_bins, \n                        orient=orient, pix_per_cell=pix_per_cell, \n                        cell_per_block=cell_per_block, \n                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n                        hist_feat=hist_feat, hog_feat=hog_feat)\nprint('Hello')\n\njoblib.dump(test_features,'test_feature.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.DataFrame()\njun = juniward_features\njmi = jmipod_features\nuer=uerd_features\ncov = cover_features\ntes = test_features\ndata['juniward'] =juniward_features\ndata['jmipod'] =jmipod_features\ndata['uerd'] =uerd_features\ndata['cover'] =cover_features\n# data['test'] = test_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('data.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install stegano\n# from stegano import lsb\nfrom scipy import spatial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dif1 = []\ndif2 = []\ndif3 = []\nfor i in range(data.shape[0]):\n    dif1.append(spatial.distance.cosine(cov[i],jun[i]))\n    dif2.append(spatial.distance.cosine(cov[i],jmi[i]))\n    dif3.append(spatial.distance.cosine(cov[i],uer[i]))\n#     print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['jun'] = dif1\ndata['jmi'] = dif2\ndata['uer'] = dif3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['mean'] = data[['jun','jmi','uer']].mean(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('data.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jes = list()\nfor i in range(data.shape[0]):\n#     print(jun[i].shape)\n    jes.append(np.sum((jun[i],jmi[i],uer[i]),axis = 0)/3)\n#     print()\n\ndata['mean_hog']= jes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.concatenate((juniward_features,jmipod_features,uerd_features,cover_features)).astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.concatenate((jes,cover_features)).astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit a per-column scaler\nX_scaler = StandardScaler().fit(X)\n# Apply the scaler to X\nscaled_X = X_scaler.transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.full(len(jmipod_features),2)\nb = np.full(len(uerd_features),3)\nc = np.full(len(juniward_features),1)\n# a.fill(1)\n# y = np.hstack((c,a,b,np.zeros(len(cover_features))))\ny = np.hstack((np.ones(len(jes)),np.zeros(len(cover_features))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/alaska2-image-steganalysis\"\n# train_imageids = pd.Series(os.listdir(BASE_PATH + '/Cover')).sort_values(ascending=True).reset_index(drop=True)\n# test_imageids = pd.Series(os.listdir(BASE_PATH + '/Test')).sort_values(ascending=True).reset_index(drop=True)\n# cover_images_path = pd.Series(BASE_PATH + '/Cover/' + train_imageids ).sort_values(ascending=True)\n# JMIPOD_images_path = pd.Series(BASE_PATH + '/JMiPOD/'+train_imageids).sort_values(ascending=True)\n# JUNIWARD_images_path = pd.Series(BASE_PATH + '/JUNIWARD/'+train_imageids).sort_values(ascending=True)\n# UERD_images_path = pd.Series(BASE_PATH + '/UERD/'+train_imageids).sort_values(ascending=True)\n# test_images_path = pd.Series(BASE_PATH + '/Test/'+test_imageids).sort_values(ascending=True)\nss = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! git clone https://github.com/dwgoon/jpegio\n!pip install jpegio/.\nimport jpegio as jio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nlgbm_params =  {\n#     'n_estimators':3000,\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'multiclass',\n    'num_class': 7,\n    'metric': ['multi_error'],\n    \"learning_rate\": 0.05,\n     \"num_leaves\": 60,\n     \"max_depth\": 9,\n     \"feature_fraction\": 0.45,\n     \"bagging_fraction\": 0.3,\n     \"reg_alpha\": 0.15,\n     \"reg_lambda\": 0.15,\n#      \"min_split_gain\": 0,\n      \"min_child_weight\": 0\n                }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\ncoverPixels = np.array(Image.open(cover_images_path[0])).astype('float')\nstegoPixels = np.array(Image.open(JUNIWARD_images_path[0])).astype('float')\n\npixelsDiff = coverPixels - stegoPixels\n\n# So since they are not the same Images the pixels_diff would not be zero\nprint(len(pixelsDiff[np.where(pixelsDiff!=0)]))\nprint(np.unique(pixelsDiff))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nlgtrain = lgb.Dataset(scaled_X,y, categorical_feature= \"auto\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR as SVC\nfrom sklearn.ensemble import RandomForestClassifier as rfc\n# from sklearn.naive_bayes import GaussianNB as nb\n# from sklearn.linear_model import LinearRegression as lr\n# from sklearn.linear_model import LogisticRegression as lr\n# Split up data into randomized training and test sets\nrand_state = np.random.randint(0, 100)\nX_train, X_test, y_train, y_test = train_test_split(\n    scaled_X, y, test_size=0.2, random_state=rand_state)\n\nprint('Using:',orient,'orientations',pix_per_cell,\n    'pixels per cell and', cell_per_block,'cells per block')\nprint('Feature vector length:', len(X_train[0]))\n# Use a linear SVC \n# svc = rfc(n_estimators=3000,n_jobs=-1,random_state=rand_state)\n# svc = LGBMClassifier(**lgbm_params)\nsvc = SVC()\n# svc = lr()\n# Check the training time for the SVC\nt=time.time()\n# svc.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_test,y_test)],\n#               verbose=100, early_stopping_rounds=100)\nsvc.fit(X_train, y_train)\nt2 = time.time()\nprint(round(t2-t, 2), 'Seconds to train SVC...')\n# Check the score of the SVC\nprint('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n# Check the prediction time for a single sample\nt=time.time()\nn_predict = 10\nprint('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\nprint('For these',n_predict, 'labels: ', y_test[0:n_predict])\nt2 = time.time()\nprint(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n\n#Tried YCrCb, 8, 1 _ good performance \n#Tried YCrCb, 8, 2 _ good performance but very slow\n","execution_count":74,"outputs":[{"output_type":"stream","text":"Using: 18 orientations 64 pixels per cell and 1 cells per block\nFeature vector length: 3456\n34.12 Seconds to train SVC...\nTest Accuracy of SVC =  0.8338\nMy SVC predicts:  [ 0.99219042  0.34137831  0.99800797 -0.20344753 -0.28358846  0.93858582\n  0.25476044  0.90285269  1.06855699  1.06101569]\nFor these 10 labels:  [1. 0. 1. 0. 0. 1. 0. 1. 1. 1.]\n0.10559 Seconds to predict 10 labels with SVC\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['Label'] = 1-svc.predict(test_features)","execution_count":75,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc.predict_proba(test_features[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv',index = False)","execution_count":76,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['Label'].min()","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"0.0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}